+++
title = "Kubeflow for Amazon SageMaker"
description = "Manage your Amazon SageMaker resources from your kubernetes cluster with the Kubeflow Pipeline Components and ACK operators bundled into this distribution."
weight = 10
+++

The latest release of Kubeflow Distribution for AWS packages together the various AWS offerings on Kubeflow for a seamless user experience. You can now install the AWS distribution of Kubeflow, the SageMaker Components for Kubeflow Pipelines and the ACK operators for SageMaker all in one go using any of the available deployment options. For a step by step guide on the installation instructions please follow the guide here.


## SageMaker Components for Kubeflow Pipelines

The [SageMaker Components for Kubeflow Pipelines](https://docs.aws.amazon.com/sagemaker/latest/dg/kubernetes-sagemaker-components-for-kubeflow-pipelines.html) allow you to move your data processing and training jobs from the Kubernetes cluster to SageMakerâ€™s machine learning-optimized managed service. 

These components integrate SageMaker with the portability and orchestration of Kubeflow Pipelines. Using the SageMaker components, each of the jobs in the pipeline workflow runs on SageMaker instead of the local Kubernetes cluster. The job parameters, status, logs, and outputs from SageMaker are still accessible from the Kubeflow Pipelines UI. The following SageMaker components have been created to integrate six key SageMaker features into your ML workflows. You can create a Kubeflow Pipeline built entirely using these components, or integrate individual components into your workflow as needed.

* [Training](https://github.com/kubeflow/pipelines/tree/master/components/aws/sagemaker/train)
* [Hyperparameter Optimization](https://github.com/kubeflow/pipelines/tree/master/components/aws/sagemaker/hyperparameter_tuning)
* [Processing](https://github.com/kubeflow/pipelines/tree/master/components/aws/sagemaker/process)
* [Hosting Deploy](https://github.com/kubeflow/pipelines/tree/master/components/aws/sagemaker/deploy)
* [Batch Transform component](https://github.com/kubeflow/pipelines/tree/master/components/aws/sagemaker/batch_transform)
* [Ground Truth](https://github.com/kubeflow/pipelines/tree/master/components/aws/sagemaker/ground_truth)
* [Workteam](https://github.com/kubeflow/pipelines/tree/master/components/aws/sagemaker/workteam)

To make it easier to try these componets out, the Kubeflow distribition for AWS includes pipeline tutorials for these SageMaker components. Examples have been included for the most common features that can be used to run production loads with just a few clicks. 

To try it out, deploy kubeflow on your cluster using the provided guides. Once installed, visit the Kubeflow Dashboard, `Pipelines` tab. <todo Meghna>

## AWS Controllers for Kubernetes (ACK) for Amazon SageMaker

The [ACK Operators for SageMaker](https://aws-controllers-k8s.github.io/community/docs/tutorials/sagemaker-example/) make it easier for developers and data scientists using Kubernetes to train, tune, and deploy machine learning (ML) models in SageMaker. [ACK](https://aws-controllers-k8s.github.io/community/docs/community/overview/) lets you define and use AWS service resources directly from Kubernetes. With ACK, you can take advantage of AWS-managed services for your Kubernetes applications without needing to define resources outside of the cluster or run services that provide supporting capabilities like databases or message queues within the cluster.

The Kubeflow Distribution for AWS bundles with it kustomize and helm templates which make it easy to deploy the ACK operators for SageMaker. Once installed, you can use ACK to manage your SageMaker resources not only from your kubernetes cluster directly but also from the Kubeflow notebooks by spawning one of our AWS optimized DLC based images. 

To try it out, follow the steps below - <todo Kartik>

